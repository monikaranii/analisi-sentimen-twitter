{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import library yang akan digunakan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Gx1eViXgjhkr"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import argparse\n",
    "import string\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.tokenize import regexp_tokenize\n",
    "from datetime import datetime\n",
    "import pytz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "KuW8gH3cjhk4",
    "outputId": "ce39eb97-3323-4d7a-c8aa-1f40aed1319d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>tanggal</th>\n",
       "      <th>tweet</th>\n",
       "      <th>sentimen</th>\n",
       "      <th>angka</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pkmjangkar</td>\n",
       "      <td>3/7/2022 23:58</td>\n",
       "      <td>update jadwal vaksinasi covid 19 upt puskesmas...</td>\n",
       "      <td>positif</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CNNIndonesia</td>\n",
       "      <td>3/7/2022 23:57</td>\n",
       "      <td>syarat jalan polymerase chain reaction antigen...</td>\n",
       "      <td>netral</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DindaNatasha15</td>\n",
       "      <td>3/7/2022 23:56</td>\n",
       "      <td>perintah pasti vaksin covid 19 bukti aman uji ...</td>\n",
       "      <td>positif</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>juvejack</td>\n",
       "      <td>3/7/2022 23:49</td>\n",
       "      <td>menko maritim investasi luhut pandjaitan tanga...</td>\n",
       "      <td>netral</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nengsunshine</td>\n",
       "      <td>3/7/2022 23:47</td>\n",
       "      <td>ok google negatif covid vaksin</td>\n",
       "      <td>netral</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         username         tanggal  \\\n",
       "0      pkmjangkar  3/7/2022 23:58   \n",
       "1    CNNIndonesia  3/7/2022 23:57   \n",
       "2  DindaNatasha15  3/7/2022 23:56   \n",
       "3        juvejack  3/7/2022 23:49   \n",
       "4    nengsunshine  3/7/2022 23:47   \n",
       "\n",
       "                                               tweet sentimen  angka  \n",
       "0  update jadwal vaksinasi covid 19 upt puskesmas...  positif      2  \n",
       "1  syarat jalan polymerase chain reaction antigen...   netral      1  \n",
       "2  perintah pasti vaksin covid 19 bukti aman uji ...  positif      2  \n",
       "3  menko maritim investasi luhut pandjaitan tanga...   netral      1  \n",
       "4                     ok google negatif covid vaksin   netral      1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_frame = pd.read_csv('data_cov.csv')\n",
    "data_frame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "wx5SySKo_kvo"
   },
   "outputs": [],
   "source": [
    "data = data_frame['tweet'].values.tolist()\n",
    "labels = data_frame['angka'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "id": "Pduz91hcjhlb",
    "outputId": "08d71039-b35c-4f7a-9aca-82cddf29c673"
   },
   "outputs": [],
   "source": [
    "train_X, test_X, y_train, y_test = train_test_split(data, labels, test_size=0.2, \n",
    "                                                    random_state=42, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Berikut adalah pola default untuk tokenisasi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_pattern =  r\"\"\"(?x)                  \n",
    "                        (?:[A-Z]\\.)+          \n",
    "                        |\\$?\\d+(?:\\.\\d+)?%?    \n",
    "                        |\\w+(?:[-']\\w+)*      \n",
    "                        |\\.\\.\\.               \n",
    "                        |(?:[.,;\"'?():-_`])    \n",
    "                    \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## funtion untuk tokenisasi data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text, pattern = default_pattern):\n",
    "    text = text.lower()\n",
    "    return regexp_tokenize(text, pattern)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize train dan test text menjadi tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "fCTB0sWwjhl7"
   },
   "outputs": [],
   "source": [
    "tokenized_text = []\n",
    "for i in range(0, len(train_X)):\n",
    "    tokenized_text.append(tokenize(train_X[i]))\n",
    "\n",
    "X_train = tokenized_text\n",
    "\n",
    "\n",
    "tokenized_text = []\n",
    "for i in range(0, len(test_X)):\n",
    "    tokenized_text.append(tokenize(test_X[i]))\n",
    "\n",
    "X_test = tokenized_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Untuk membuat kamus token dari data\n",
    "## data dalam tipe - daftar\n",
    "## Kamus token yang diurutkan dan jumlahnya dalam data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "pFyEv5ERPuB3"
   },
   "outputs": [],
   "source": [
    "def createDictionary(data):\n",
    "    dictionary = dict()\n",
    "    for sample in  data:\n",
    "        for token in sample:\n",
    "            dictionary[token] = dictionary.get(token, 0) + 1\n",
    "    sorted_dict = sorted(dictionary.items(), key=lambda x: x[1], reverse=True)\n",
    "    return dict(sorted_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "auz1uD0IjhmI",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class NBClassifier:\n",
    "\n",
    "    def __init__(self, X_train, y_train, size):\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        self.size = size\n",
    "\n",
    "# Untuk membuat kamus token dari data\n",
    "# data dalam tipe - daftar\n",
    "# Kamus yang diurutkan dari token dan jumlah mereka dalam data\n",
    "    def createDictionary(self):\n",
    "        dictionary = dict()\n",
    "        for sample in  X_train:\n",
    "            for token in sample:\n",
    "                dictionary[token] = dictionary.get(token, 0) + 1\n",
    "        sorted_dict = sorted(dictionary.items(), key=lambda x: x[1], reverse=True)\n",
    "        return dict(sorted_dict)\n",
    "# Untuk menghitung jumlah kata dalam kamus data pelatihan\n",
    "# Trianing data & Ukuran kamus\n",
    "# kamus token dengan probabilitas bijaksana kelasnya \n",
    "    def fit(self):\n",
    "      \n",
    "        X_train_dict = self.createDictionary()\n",
    "        if self.size == 'full':\n",
    "            self.words_list = list(X_train_dict.keys())\n",
    "            self.words_count = dict.fromkeys(self.words_list, None)\n",
    "        else:\n",
    "            self.words_list = list(X_train_dict.keys())[:int(self.size)]\n",
    "            self.words_count = dict.fromkeys(self.words_list, None)\n",
    "            \n",
    "        train = pd.DataFrame(columns = ['X_train', 'y_train'])\n",
    "        train['X_train'] = X_train\n",
    "        train['y_train'] = y_train\n",
    "\n",
    "        train_0 = train.copy()[train['y_train'] == 0]\n",
    "        train_1 = train.copy()[train['y_train'] == 1]\n",
    "        train_2 = train.copy()[train['y_train'] == 2]\n",
    "        \n",
    "        Pr0 = train_0.shape[0]/train.shape[0]\n",
    "        Pr1 = train_1.shape[0]/train.shape[0]\n",
    "        Pr2 = train_2.shape[0]/train.shape[0]\n",
    "\n",
    "        self.Prior = np.array([Pr0, Pr1, Pr2])\n",
    "\n",
    "        def flatList(listOfList):\n",
    "            flatten = []\n",
    "            for elem in listOfList:\n",
    "                flatten.extend(elem)\n",
    "            return flatten\n",
    " \n",
    "        X_train_0 = flatList(train[train['y_train'] == 0]['X_train'].tolist())\n",
    "        X_train_1 = flatList(train[train['y_train'] == 1]['X_train'].tolist())\n",
    "        X_train_2 = flatList(train[train['y_train'] == 2]['X_train'].tolist())\n",
    "\n",
    "        self.X_train_len = np.array([len(X_train_0), len(X_train_1), len(X_train_2)])\n",
    "\n",
    "        for token in self.words_list:\n",
    "          \n",
    "            res = [] #list untuk menyimpan label\n",
    "\n",
    "            res.insert(0, X_train_0.count(token))\n",
    "\n",
    "\n",
    "            res.insert(1, X_train_1.count(token))\n",
    "\n",
    "            res.insert(2, X_train_2.count(token))\n",
    "\n",
    "\n",
    "            self.words_count[token] = res\n",
    "        return self\n",
    "# Memprediksi label data\n",
    "# menghitung data uji\n",
    "# Daftar label yang diprediksi untuk data uji\n",
    "    def predict(self, X_test):\n",
    "        pred = []\n",
    "        for sample in X_test:\n",
    "            mul = np.array([1,1,1])\n",
    "            for tokens in sample:\n",
    "                vocab_count = len(self.words_list)\n",
    "                if tokens in self.words_list:\n",
    "                    prob = ((np.array(self.words_count[tokens])+1) / (self.X_train_len + vocab_count))\n",
    "                mul = mul * prob\n",
    "            val = mul * self.Prior\n",
    "            pred.append(np.argmax(val))\n",
    "        return pred\n",
    "# Untuk menghitung kinerja\n",
    "# label yang diprediksi, dan label aktual dari data uji\n",
    "# Jumlah label yang diprediksi dengan benar dan akurasi\n",
    "    def score(self, pred, labels):\n",
    "\n",
    "        correct = (np.array(pred) == np.array(labels)).sum()\n",
    "        accuracy = correct/len(pred)\n",
    "        return correct, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "mYOgoiHUchMA"
   },
   "outputs": [],
   "source": [
    "# Creating holders to store the model performance results\n",
    "attributes = []\n",
    "corr = []\n",
    "acc = []\n",
    "\n",
    "#function to call for storing the results\n",
    "def storeResults(attr, cor,ac):\n",
    "    attributes.append(attr)\n",
    "    corr.append(round(cor, 3))\n",
    "    acc.append(round(ac, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "id": "n0TqGF2sjhmN",
    "outputId": "413adf02-f940-45ee-b784-b817abd4ebc9"
   },
   "outputs": [],
   "source": [
    "#training the classifier     \n",
    "nb = NBClassifier(X_train, y_train, 'full')  \n",
    "nb.fit()\n",
    "y_pred = nb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix\n",
      "[[  8   5   2]\n",
      " [ 21 120  11]\n",
      " [  0   6  36]]\n",
      "\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      0.53      0.36        15\n",
      "           1       0.92      0.79      0.85       152\n",
      "           2       0.73      0.86      0.79        42\n",
      "\n",
      "    accuracy                           0.78       209\n",
      "   macro avg       0.64      0.73      0.67       209\n",
      "weighted avg       0.83      0.78      0.80       209\n",
      "\n",
      "\n",
      "Accuracy\n",
      "78.4688995215311 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "print(\"\\nConfusion Matrix\")\n",
    "print(confusion_matrix(y_pred, y_test))\n",
    "\n",
    "print(\"\\nClassification Report\")\n",
    "print(classification_report(y_pred, y_test))\n",
    "\n",
    "print(\"\\nAccuracy\")\n",
    "print(accuracy_score(y_pred, y_test)*100, '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "US Airlines Sentiment Classification.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
