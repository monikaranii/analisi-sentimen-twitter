{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import library yang akan digunakan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "Gx1eViXgjhkr"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import argparse\n",
    "import string\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.tokenize import regexp_tokenize\n",
    "from datetime import datetime\n",
    "import pytz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 447
    },
    "id": "KuW8gH3cjhk4",
    "outputId": "ce39eb97-3323-4d7a-c8aa-1f40aed1319d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>username</th>\n",
       "      <th>tanggal</th>\n",
       "      <th>tweet</th>\n",
       "      <th>sentimen</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>pkmjangkar</td>\n",
       "      <td>3/7/2022 23:58</td>\n",
       "      <td>update jadwal vaksinasi covid 19 upt puskesmas...</td>\n",
       "      <td>positif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CNNIndonesia</td>\n",
       "      <td>3/7/2022 23:57</td>\n",
       "      <td>syarat jalan polymerase chain reaction antigen...</td>\n",
       "      <td>netral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DindaNatasha15</td>\n",
       "      <td>3/7/2022 23:56</td>\n",
       "      <td>perintah pasti vaksin covid 19 bukti aman uji ...</td>\n",
       "      <td>positif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>juvejack</td>\n",
       "      <td>3/7/2022 23:49</td>\n",
       "      <td>menko maritim investasi luhut pandjaitan tanga...</td>\n",
       "      <td>netral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>nengsunshine</td>\n",
       "      <td>3/7/2022 23:47</td>\n",
       "      <td>ok google negatif covid vaksin</td>\n",
       "      <td>netral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         username         tanggal  \\\n",
       "0      pkmjangkar  3/7/2022 23:58   \n",
       "1    CNNIndonesia  3/7/2022 23:57   \n",
       "2  DindaNatasha15  3/7/2022 23:56   \n",
       "3        juvejack  3/7/2022 23:49   \n",
       "4    nengsunshine  3/7/2022 23:47   \n",
       "\n",
       "                                               tweet sentimen  \n",
       "0  update jadwal vaksinasi covid 19 upt puskesmas...  positif  \n",
       "1  syarat jalan polymerase chain reaction antigen...   netral  \n",
       "2  perintah pasti vaksin covid 19 bukti aman uji ...  positif  \n",
       "3  menko maritim investasi luhut pandjaitan tanga...   netral  \n",
       "4                     ok google negatif covid vaksin   netral  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_frame = pd.read_csv('hasil labeling data.csv')\n",
    "data_frame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    645\n",
       "2    250\n",
       "0    157\n",
       "Name: sentimen, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#repalcing the categorical values of 'airline_sentiment' to numeric values\n",
    "data_frame['sentimen'].replace(('negatif', 'netral', 'positif'), (0, 1, 2), inplace=True)\n",
    "data_frame['sentimen'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "wx5SySKo_kvo"
   },
   "outputs": [],
   "source": [
    "data = data_frame['tweet'].values.tolist()\n",
    "labels = data_frame['sentimen'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "id": "Pduz91hcjhlb",
    "outputId": "08d71039-b35c-4f7a-9aca-82cddf29c673"
   },
   "outputs": [],
   "source": [
    "train_X, test_X, y_train, y_test = train_test_split(data, labels, test_size=0.2, \n",
    "                                                    random_state=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Berikut adalah pola default untuk tokenisasi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_pattern =  r\"\"\"(?x)                  \n",
    "                        (?:[A-Z]\\.)+          \n",
    "                        |\\$?\\d+(?:\\.\\d+)?%?    \n",
    "                        |\\w+(?:[-']\\w+)*      \n",
    "                        |\\.\\.\\.               \n",
    "                        |(?:[.,;\"'?():-_`])    \n",
    "                    \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## funtion untuk tokenisasi data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text, pattern = default_pattern):\n",
    "    text = text.lower()\n",
    "    return regexp_tokenize(text, pattern)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenize train dan test text menjadi tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "fCTB0sWwjhl7"
   },
   "outputs": [],
   "source": [
    "tokenized_text = []\n",
    "for i in range(0, len(train_X)):\n",
    "    tokenized_text.append(tokenize(train_X[i]))\n",
    "\n",
    "X_train = tokenized_text\n",
    "\n",
    "\n",
    "tokenized_text = []\n",
    "for i in range(0, len(test_X)):\n",
    "    tokenized_text.append(tokenize(test_X[i]))\n",
    "\n",
    "X_test = tokenized_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Untuk membuat kamus token dari data\n",
    "## data dalam tipe - daftar\n",
    "## Kamus token yang diurutkan dan jumlahnya dalam data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "pFyEv5ERPuB3"
   },
   "outputs": [],
   "source": [
    "def createDictionary(data):\n",
    "    dictionary = dict()\n",
    "    for sample in  data:\n",
    "        for token in sample:\n",
    "            dictionary[token] = dictionary.get(token, 0) + 1\n",
    "    sorted_dict = sorted(dictionary.items(), key=lambda x: x[1], reverse=True)\n",
    "    return dict(sorted_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "auz1uD0IjhmI",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "class NBClassifier:\n",
    "\n",
    "    def __init__(self, X_train, y_train, size):\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        self.size = size\n",
    "\n",
    "# Untuk membuat kamus token dari data\n",
    "# data dalam tipe - daftar\n",
    "# Kamus yang diurutkan dari token dan jumlah mereka dalam data\n",
    "    def createDictionary(self):\n",
    "        dictionary = dict()\n",
    "        for sample in  X_train:\n",
    "            for token in sample:\n",
    "                dictionary[token] = dictionary.get(token, 0) + 1\n",
    "        sorted_dict = sorted(dictionary.items(), key=lambda x: x[1], reverse=True)\n",
    "        return dict(sorted_dict)\n",
    "# Untuk menghitung jumlah kata dalam kamus data pelatihan\n",
    "# Trianing data & Ukuran kamus\n",
    "# kamus token dengan probabilitas bijaksana kelasnya \n",
    "    def fit(self):\n",
    "      \n",
    "        X_train_dict = self.createDictionary()\n",
    "        if self.size == 'full':\n",
    "            self.words_list = list(X_train_dict.keys())\n",
    "            self.words_count = dict.fromkeys(self.words_list, None)\n",
    "        else:\n",
    "            self.words_list = list(X_train_dict.keys())[:int(self.size)]\n",
    "            self.words_count = dict.fromkeys(self.words_list, None)\n",
    "            \n",
    "        train = pd.DataFrame(columns = ['X_train', 'y_train'])\n",
    "        train['X_train'] = X_train\n",
    "        train['y_train'] = y_train\n",
    "\n",
    "        train_0 = train.copy()[train['y_train'] == 0]\n",
    "        train_1 = train.copy()[train['y_train'] == 1]\n",
    "        train_2 = train.copy()[train['y_train'] == 2]\n",
    "        \n",
    "        Pr0 = train_0.shape[0]/train.shape[0]\n",
    "        Pr1 = train_1.shape[0]/train.shape[0]\n",
    "        Pr2 = train_2.shape[0]/train.shape[0]\n",
    "\n",
    "        self.Prior = np.array([Pr0, Pr1, Pr2])\n",
    "\n",
    "        def flatList(listOfList):\n",
    "            flatten = []\n",
    "            for elem in listOfList:\n",
    "                flatten.extend(elem)\n",
    "            return flatten\n",
    " \n",
    "        X_train_0 = flatList(train[train['y_train'] == 0]['X_train'].tolist())\n",
    "        X_train_1 = flatList(train[train['y_train'] == 1]['X_train'].tolist())\n",
    "        X_train_2 = flatList(train[train['y_train'] == 2]['X_train'].tolist())\n",
    "\n",
    "        self.X_train_len = np.array([len(X_train_0), len(X_train_1), len(X_train_2)])\n",
    "\n",
    "        for token in self.words_list:\n",
    "          \n",
    "            res = [] #list untuk menyimpan label\n",
    "\n",
    "            res.insert(0, X_train_0.count(token))\n",
    "\n",
    "\n",
    "            res.insert(1, X_train_1.count(token))\n",
    "\n",
    "            res.insert(2, X_train_2.count(token))\n",
    "\n",
    "\n",
    "            self.words_count[token] = res\n",
    "        return self\n",
    "# Memprediksi label data\n",
    "# menghitung data uji\n",
    "# Daftar label yang diprediksi untuk data uji\n",
    "    def predict(self, X_test):\n",
    "        pred = []\n",
    "        for sample in X_test:\n",
    "            mul = np.array([1,1,1])\n",
    "            for tokens in sample:\n",
    "                vocab_count = len(self.words_list)\n",
    "                if tokens in self.words_list:\n",
    "                    prob = ((np.array(self.words_count[tokens])+1) / (self.X_train_len + vocab_count))\n",
    "                mul = mul * prob\n",
    "            val = mul * self.Prior\n",
    "            pred.append(np.argmax(val))\n",
    "        return pred\n",
    "# Untuk menghitung kinerja\n",
    "# label yang diprediksi, dan label aktual dari data uji\n",
    "# Jumlah label yang diprediksi dengan benar dan akurasi\n",
    "    def score(self, pred, labels):\n",
    "\n",
    "        correct = (np.array(pred) == np.array(labels)).sum()\n",
    "        accuracy = correct/len(pred)\n",
    "        return correct, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "mYOgoiHUchMA"
   },
   "outputs": [],
   "source": [
    "# Creating holders to store the model performance results\n",
    "attributes = []\n",
    "corr = []\n",
    "acc = []\n",
    "\n",
    "#function to call for storing the results\n",
    "def storeResults(attr, cor,ac):\n",
    "    attributes.append(attr)\n",
    "    corr.append(round(cor, 3))\n",
    "    acc.append(round(ac, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 69
    },
    "id": "n0TqGF2sjhmN",
    "outputId": "413adf02-f940-45ee-b784-b817abd4ebc9"
   },
   "outputs": [],
   "source": [
    "#training the classifier     \n",
    "nb = NBClassifier(X_train, y_train, 'full')  \n",
    "nb.fit()\n",
    "y_pred = nb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix\n",
      "[[ 11   7   1]\n",
      " [ 15 110  13]\n",
      " [  1  14  39]]\n",
      "\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      0.58      0.48        19\n",
      "           1       0.84      0.80      0.82       138\n",
      "           2       0.74      0.72      0.73        54\n",
      "\n",
      "    accuracy                           0.76       211\n",
      "   macro avg       0.66      0.70      0.68       211\n",
      "weighted avg       0.77      0.76      0.76       211\n",
      "\n",
      "\n",
      "Accuracy\n",
      "75.82938388625593 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "print(\"\\nConfusion Matrix\")\n",
    "print(confusion_matrix(y_pred, y_test))\n",
    "\n",
    "print(\"\\nClassification Report\")\n",
    "print(classification_report(y_pred, y_test))\n",
    "\n",
    "print(\"\\nAccuracy\")\n",
    "print(accuracy_score(y_pred, y_test)*100, '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "US Airlines Sentiment Classification.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
